{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48cf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchsummary # 모델 구조 보기좋게 출력\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "from torchvision.utils import *\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6f659",
   "metadata": {},
   "source": [
    "# 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b494e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device 세팅\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fab753",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6219e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResModule(in_chnnel, out_chnnel):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_chnnel, out_chnnel,(3, 3), padding = 1),\n",
    "        torch.nn.BatchNorm2d(out_chnnel),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d((2, 2))\n",
    "    )\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    ResModule(3, 64),\n",
    "    ResModule(64, 128),\n",
    "    ResModule(128, 256),\n",
    "    ResModule(256, 128),\n",
    "    torch.nn.AdaptiveMaxPool2d(output_size=(1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(128, 10, bias = True)\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16,(3, 3), padding = 1),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    torch.nn.Conv2d(16, 16,(3, 3), padding = 1),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    torch.nn.Conv2d(16, 32,(3, 3), padding = 1),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    torch.nn.Conv2d(32, 16,(3, 3), padding = 1),\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "    torch.nn.AdaptiveMaxPool2d(output_size=(1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(16, 10, bias = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dd00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfe421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 64, 64]             448\n",
      "       BatchNorm2d-2           [-1, 16, 64, 64]              32\n",
      "              ReLU-3           [-1, 16, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 16, 32, 32]               0\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "              ReLU-7           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
      "            Conv2d-9           [-1, 32, 16, 16]           4,640\n",
      "      BatchNorm2d-10           [-1, 32, 16, 16]              64\n",
      "             ReLU-11           [-1, 32, 16, 16]               0\n",
      "        MaxPool2d-12             [-1, 32, 8, 8]               0\n",
      "           Conv2d-13             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-14             [-1, 16, 8, 8]              32\n",
      "             ReLU-15             [-1, 16, 8, 8]               0\n",
      "        MaxPool2d-16             [-1, 16, 4, 4]               0\n",
      "AdaptiveMaxPool2d-17             [-1, 16, 1, 1]               0\n",
      "          Flatten-18                   [-1, 16]               0\n",
      "           Linear-19                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 12,362\n",
      "Trainable params: 12,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.26\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 2.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torchsummary.summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32268864",
   "metadata": {},
   "source": [
    "# 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee15689a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pathlib.Path('./train').mkdir(parents = True, exist_ok=True)\n",
    "pathlib.Path('./test').mkdir(parents = True, exist_ok=True)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize([64, 64]),\n",
    "    torchvision.transforms.Normalize((0.485*255, 0.456*255, 0.406*255), (0.229, 0.224, 0.225))\n",
    "])\n",
    "train_dataset = torchvision.datasets.STL10('/train', split='train', download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.STL10('/test', split='test', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c59a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd23374",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ccbbf9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val(model, params):\n",
    "    device = params[\"device\"]\n",
    "    validation_dataloader = params[\"val_dataloader\"]\n",
    "    loss_function = params[\"loss_function_generator\"]()\n",
    "    model.to(device)\n",
    "    \n",
    "    total = 0\n",
    "    right = 0\n",
    "    loss = 0\n",
    "\n",
    "    for input_batch, label_batch in validation_dataloader:\n",
    "        input_batch = input_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "        \n",
    "        length = len(input_batch)\n",
    "        total += length\n",
    "        \n",
    "        predict = model(input_batch)\n",
    "        new_loss = loss_function(predict, label_batch)\n",
    "        \n",
    "        loss = new_loss+ (new_loss-loss)*length/total\n",
    "        predict_class = torch.max(predict, 1)[1]\n",
    "        right += (predict_class == label_batch).sum().item()\n",
    "        \n",
    "    acc = right/total\n",
    "    print(right, total)\n",
    "    return acc, loss\n",
    " \n",
    "\n",
    "\n",
    "def train(model, params):\n",
    "    device = params[\"device\"]\n",
    "    train_dataloader = params[\"train_dataloader\"] \n",
    "    val_dataloader = params[\"val_dataloader\"]\n",
    "    \n",
    "    epoch = params[\"epoch\"]\n",
    "    lr = params[\"learning_rate\"]\n",
    "    \n",
    "    optimizer = params[\"optimizer_generator\"](model.parameters(), lr = lr)\n",
    "    loss_function = params[\"loss_function_generator\"]().to(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        for input_batch, label_batch in train_dataloader:\n",
    "            input_batch = input_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(input_batch)\n",
    "            loss = loss_function(predict, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(val(model, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4aee087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2129 8000\n",
      "(0.266125, tensor(1.9365, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2251 8000\n",
      "(0.281375, tensor(1.9042, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2247 8000\n",
      "(0.280875, tensor(1.8579, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2440 8000\n",
      "(0.305, tensor(1.8470, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2518 8000\n",
      "(0.31475, tensor(1.8057, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2647 8000\n",
      "(0.330875, tensor(1.7854, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2721 8000\n",
      "(0.340125, tensor(1.7667, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2742 8000\n",
      "(0.34275, tensor(1.7401, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2795 8000\n",
      "(0.349375, tensor(1.6816, device='cuda:0', grad_fn=<AddBackward0>))\n",
      "2794 8000\n",
      "(0.34925, tensor(1.6701, device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"device\":device,\n",
    "    \n",
    "    \"train_dataloader\":train_dataloader,\n",
    "    \"val_dataloader\":test_dataloader,\n",
    "\n",
    "    \"epoch\": 10,\n",
    "    \"learning_rate\":0.0001,\n",
    "    \n",
    "    \"optimizer_generator\": torch.optim.Adam,\n",
    "    \"loss_function_generator\":torch.nn.CrossEntropyLoss\n",
    "}\n",
    "\n",
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7332b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea790ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "754ea6ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.00 GiB total capacity; 9.25 GiB already allocated; 0 bytes free; 9.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m:device,\n\u001b[0;32m      3\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_function_generator\u001b[39m\u001b[38;5;124m\"\u001b[39m:torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet50()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [38], line 54\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     51\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn [38], line 18\u001b[0m, in \u001b[0;36mval\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     15\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_batch)\n\u001b[0;32m     16\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m---> 18\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m new_loss \u001b[38;5;241m=\u001b[39m loss_function(predict, label_batch)\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m new_loss\u001b[38;5;241m+\u001b[39m (new_loss\u001b[38;5;241m-\u001b[39mloss)\u001b[38;5;241m*\u001b[39mlength\u001b[38;5;241m/\u001b[39mtotal\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\resnet.py:271\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m--> 271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_jit_internal.py:485\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.00 GiB total capacity; 9.25 GiB already allocated; 0 bytes free; 9.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"device\":device,\n",
    "    \n",
    "    \"train_dataloader\":train_dataloader,\n",
    "    \"val_dataloader\":test_dataloader,\n",
    "\n",
    "    \"epoch\": 10,\n",
    "    \"learning_rate\":0.0001,\n",
    "    \n",
    "    \"optimizer_generator\": torch.optim.Adam,\n",
    "    \"loss_function_generator\":torch.nn.CrossEntropyLoss\n",
    "}\n",
    "model = models.resnet50()\n",
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d3940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960910c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1add1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a2e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66652df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192e7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53fe31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'train_dataloader':train_dataloader,\n",
    "    'test_dataloader': test_dataloader,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37039896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    train_dataloader=params[\"train_dataloader\"]\n",
    "    test_dataloader=params[\"test_dataloader\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # train dataloader 로 불러온 데이터에서 이미지와 라벨을 분리\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 이전 batch에서 계산된 가중치를 초기화\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + back propagation 연산\n",
    "            outputs = model(inputs)\n",
    "            train_loss = loss_function(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # test accuracy 계산\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        accuracy = []\n",
    "        \n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 결과값 연산\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss = loss_function(outputs, labels).item()\n",
    "            accuracy.append(100 * correct/total)\n",
    "\n",
    "        # 학습 결과 출력\n",
    "        print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73dc1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Train loss: 2.218821, Test loss: 2.384054, Accuracy: 10.00\n",
      "Epoch: 2/5, Train loss: 2.280489, Test loss: 2.325967, Accuracy: 10.00\n",
      "Epoch: 3/5, Train loss: 2.298495, Test loss: 2.316422, Accuracy: 12.88\n",
      "Epoch: 4/5, Train loss: 2.233734, Test loss: 2.285816, Accuracy: 13.19\n",
      "Epoch: 5/5, Train loss: 2.257638, Test loss: 2.123544, Accuracy: 18.90\n"
     ]
    }
   ],
   "source": [
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d09d7ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2951394079.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    model[]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f5455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
